{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Get the Weak Lensing Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will use the things described in the last two sessions and make a weak lensing measurement pipeline for ourselves. We will start with writing out the different steps required to get the pipeline ready. We then code up each of them as individual functions, which will be called in our main code.\n",
    "\n",
    "**We highly suggest readers to make a separate notebook for this session as it will be useful for later use.** \n",
    "\n",
    "\n",
    "**In the codes below I have left some black spaces indicated using ??. Please fill up the ?? in the code below and make sure you are doing it with right equations and conversions.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Steps\n",
    "\n",
    "- Reading data from the catalog and appying the selection cuts.\n",
    "\n",
    "- Computing the tangential shear $e_{\\rm t}$ and inverse critical density $\\Sigma^{-1}_{\\rm crit}$. \n",
    "\n",
    "- $\\Delta \\Sigma (R)$ measurements using cKDTree and writing the output to a file.\n",
    "\n",
    "- Plotting the  weak lensing signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from the catalog and appying the selection cuts.\n",
    "\n",
    "We are going to use the selection cuts on lensing sample in the day-1 session. The below code can be use for other cuts too but for now lets stick to defaults as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection cut on the lens sample\n",
    "def lens_select(zmin=0.1, zmax=0.33, lammin=55, lammax=100):\n",
    "    #please check the file path properly \n",
    "    data = pd.read_csv('/home/idies/workspace/Storage/divyar/IAGRG_2022/DataStore/redmapper.dat', delim_whitespace=1)\n",
    "    #sample selection cut\n",
    "    idx  = (data['lambda']>lammin) & (data['lambda']<=lammax)\n",
    "    idx  = idx & (data['zred']>zmin) & (data['zred']<=zmax)\n",
    "    ra   = data['ra'].values[idx]\n",
    "    dec  = data['dec'].values[idx]\n",
    "    zred = data['zred'].values[idx]\n",
    "    #as we have no weights to apply we set them to unity\n",
    "    wgt  = ra*1.0/ra\n",
    "    print('number of lenses=%d'%len(ra))\n",
    "    return ra, dec, zred, wgt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar we define a function for sources and collect the data from it.\n",
    "Please note that there are many columns in source file but for now we are only using some of them. \n",
    "Here we are only using \n",
    "\n",
    "- ra_gal, decgal : ra and dec for the sources\n",
    "- e1gal, e2gal: decribes the shapes of the sources\n",
    "- wgal, rms_egal: weights and Intrinsic shape dispersion per component\n",
    "- zphotgal: redshift of the sources\n",
    "\n",
    "For now we will neglect the data in other columns. As it is used for correcting the biases for our measurements and we will decribe how to use them at the end of this session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sources(ifil):\n",
    "    # various columns in sources \n",
    "    # ragal, decgal, e1gal, e2gal, wgal, rms_egal, mgal, c1gal, c2gal, R2gal, zphotgal\n",
    "    data = pd.read_csv(ifil, delim_whitespace=1).values\n",
    "    zphotgal = data[:,-1]\n",
    "    # sanity checks on the sources data\n",
    "    idx = (np.sum(np.isnan(data), axis=1)==0) &  (zphotgal>0)\n",
    "    datagal = np.zeros((np.sum(idx),7))\n",
    "    datagal[:,:6] = data[idx,:6]\n",
    "    datagal[:,6]  = data[idx,-1]\n",
    "    # collects only -  ragal, decgal, e1gal, e2gal, wgal, rms_egal, zphotgal\n",
    "    return datagal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the tangential shear $e_{\\rm t}$ and inverse critical density $\\Sigma^{-1}_{\\rm crit}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will follow the formalism described in Prof Surhud More's lectures. We will first code up function to compute tangential component of the ellipticity given the positions for the lenses ($\\alpha_l$, $\\delta_l$) and sources($\\alpha_s$, $\\delta_s$) along with the shape measurements ($e_1$,$e_2$) for the sources.\n",
    "\n",
    "We will first compute angle $\\theta$ between a given lens-source pair.\n",
    "$$\\cos \\theta = \\cos \\delta_l \\cos \\delta_s \\cos(\\alpha_l - \\alpha_s) + \\sin\\delta_l \\sin \\delta_s $$\n",
    "\n",
    "where $\\delta_{l,s}$ and $\\alpha_{l,s}$ are ra and dec for lens(l) and source(s). The tangential component of ellipticity $e_t$ is given as\n",
    "\n",
    "$$e_t = - e_1 \\cos 2\\phi - e_2 \\sin 2\\phi$$\n",
    "\n",
    "$$ \\sin \\phi = \\frac{-\\sin \\delta_l \\cos \\delta_s + \\cos \\delta_l \\sin \\delta_s  \\cos(\\alpha_s - \\alpha_l)}{|\\sin\\theta|} $$\n",
    "\n",
    "$$\\cos \\phi =  \\frac{\\cos\\delta_l \\sin(\\alpha_s - \\alpha_l)}{|\\sin\\theta|}$$\n",
    "\n",
    "\n",
    "For more info refer to Lecture Notes here - https://surhudm.github.io/Weaklensing_IAGRG/Weak_gravitational_lensing.html#Tangential-shear-computation\n",
    "\n",
    "\n",
    "Coding  up these equations requires trigonometric functions from numpy package. Please check them out.\n",
    "\n",
    "- sin : https://numpy.org/doc/stable/reference/generated/numpy.sin.html\n",
    "\n",
    "- cos : https://numpy.org/doc/stable/reference/generated/numpy.cos.html#numpy.cos\n",
    "\n",
    "**Please note that these functions by default uses angles in radians and here we are working with catalog data with (ra,dec) in degrees. So, we need to do the needful conversion first** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lra, ldec - lenses position\n",
    "# sra, sdec - sources position\n",
    "# se1 and se2 - source ellipticities\n",
    "def get_et(lra, ldec, sra, sdec, se1, se2):\n",
    "    # angle_in_radian = angle_in_degrees * np.pi/180\n",
    "    lra  = ??\n",
    "    # fill up the blanks\n",
    "    ldec = ??\n",
    "    sra  = ??\n",
    "    sdec = ?? \n",
    "    # c_theta = cos_theta, s_theta = sin_theta\n",
    "    # use the equations above and complete the expressions\n",
    "    c_theta = np.cos(??)*np.cos(sdec) * ?? + np.sin(ldec)*np.sin(??)\n",
    "    s_theta = np.sqrt(1-c_theta**2)\n",
    "\n",
    "    # phi to get the compute the tangential shear\n",
    "    c_phi   = ?? *1.0/s_theta\n",
    "    s_phi   = (-np.sin(ldec)*np.cos(sdec) + ?? )*1.0/s_theta\n",
    "    # tangential shear\n",
    "    e_t     = - se1*(??) - se2*(??)\n",
    "\n",
    "    return e_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Exercise: \n",
    "    \n",
    "- Tell what are you getting the output for $e_t$ if you use input lra=0.0, ldec=0.0, sra=0.123, sdec=0.045, se1 = 4.5e-2, se2 = 1.7e-2.\n",
    "- running command : **print(get_et(lra=0.0, ldec=0.0, sra=0.123, sdec=0.045, se1 = 4.5e-2, se2 = 1.7e-2))** in the next cell below the function defination cell. Please add cell below using the insert option on the top.    \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now move on to writing a function to get $\\Sigma^{-1}_{\\rm crit} (z_l,z_s)$ given the lense redshift ($z_l$) and source redshift ($z_s$) and it also needs a instance of astropy class (cc). Remember we need to create a instance for the astropy cosmo class given the input cosmological parameters. In the current code structure we will initiate the astopy cosmo class in our main code.\n",
    "\n",
    "To review you can refer to Day-1 docs page to see how astropy is used to get cosmological distances. \n",
    "Please note that here we are working in comoving coordinates to do the signal computations so the corresponding $\\Sigma^{-1}_{\\rm crit} (z_l,z_s)$ is given as\n",
    "\n",
    "$$\\Sigma^{-1}_{\\rm crit}(z_l,z_s) = \\frac{4\\pi G}{c^2} \\frac{d_{\\rm ang}(z_l) d_{\\rm ang}(z_l, z_s) (1 + z_l)^2} {d_{\\rm ang}(z_s)}$$\n",
    "\n",
    "where $d_{\\rm ang}(z)$ is the angular diameter distance for redshift $z$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma_crit_inv(lzred, szred, cc):\n",
    "    # some important constants for the sigma crit computations\n",
    "    gee = 4.301e-9 #km^2 Mpc M_sun^-1 s^-2 gravitational constant\n",
    "    cee = 3e5 #km s^-1\n",
    "    # sigma_crit_calculations for a given lense-source pair\n",
    "    sigm_crit_inv = ?? * cc.angular_diameter_distance_z1z2(lzred, szred).value * (1.0 + lzred)**?? * 1.0/cc.angular_diameter_distance(szred).value\n",
    "    sigm_crit_inv = sigm_crit_inv * 4*np.pi*gee*1.0/cee**2 \n",
    "    sigm_crit_inv = 1e12*sigm_crit_inv #esd's are in pc not in Mpc\n",
    "\n",
    "    return sigm_crit_inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Exercise: \n",
    "    \n",
    "- In the cell below the function defination, first initiate the cosmo class from astropy using \"**cc = FlatLambdaCDM(H0=100, Om0=0.999)**\".\n",
    "- running command : **print(get_sigma_crit_inv(lzred=0.33, szred=0.8, cc=cc))**  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how to convert from ra,dec (degrees) to x,y,z coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xyz(ra, dec):\n",
    "    ra = ra*np.pi/??\n",
    "    dec = dec*??\n",
    "    x = np.cos(dec)*np.cos(ra)\n",
    "    y = np.cos(??)*np.sin(??)\n",
    "    z = np.sin(dec) \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Exercise: \n",
    "    \n",
    "- Tell the output of : **print(get_xyz(30, 60))**  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta \\Sigma (R)$ measurements using cKDTree and writing the output to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipe(Omegam=0.315, rmin=0.2, rmax=2.0, nbins=10, zdiff=0.4):\n",
    "    #set the cosmology with omegaM parameter \n",
    "    cc = FlatLambdaCDM(H0=100, Om0=Omegam) # fixing H0=100 to set units in Mpc h-1\n",
    "    \n",
    "    # set the projected radial binning \n",
    "    rmin  =  rmin\n",
    "    rmax  =  rmax\n",
    "    nbins = nbins #10 radial bins for our case\n",
    "    rbins  = np.logspace(np.log10(rmin), np.log10(rmax), nbins + 1)\n",
    "    rdiff  = np.log10(rbins[1]*1.0/rbins[0])\n",
    " \n",
    "    # initializing arrays for signal compuations\n",
    "    sumdsig_num   = np.zeros(len(rbins[:-1]))\n",
    "    sumdsigsq_num = np.zeros(len(rbins[:-1]))\n",
    "    sumwls        = np.zeros(len(rbins[:-1]))\n",
    "    sumwls_resp   = np.zeros(len(rbins[:-1]))\n",
    "\n",
    "    # getting the lenses data\n",
    "    lra, ldec, lred, lwgt = lens_select()\n",
    "\n",
    "    # convert lense ra and dec into x,y,z cartesian coordinates\n",
    "    lx, ly, lz = get_xyz(lra, ldec)\n",
    "     \n",
    "    # putting kd tree around the lenses\n",
    "    lens_tree = KDTree(np.array([lx, ly, lz]).T)\n",
    "    \n",
    "    \n",
    "    print('lenses tree is ready\\n')\n",
    "    \n",
    "    # setting maximum search radius\n",
    "    dcommin = cc.comoving_distance(np.min(lred)).value\n",
    "    dismax  = (rmax*1.0/(dcommin)) \n",
    "\n",
    "    # lets first catch the file list for sources\n",
    "    sflist = np.sort(glob.glob('./DataStore/hsc/*.dat'))\n",
    "\n",
    "    # Ready to pounce on the source data\n",
    "    for ifil in sflist:\n",
    "        # catching the source data matrix\n",
    "        # please have a check for the columns names\n",
    "        datagal = read_sources(ifil)\n",
    "        Ngal = len(datagal[:,0])  # total number of galaxies in the source file\n",
    "        # first two entries are ra and dec for the sources\n",
    "        allragal  = datagal[:,0]\n",
    "        alldecgal = datagal[:,1]\n",
    "        # ra and dec to x,y,z for sources\n",
    "        allsx, allsy, allsz = get_xyz(allragal, alldecgal)\n",
    "        # query in a ball around individual sources and collect the lenses ids with a maximum radius\n",
    "        slidx = lens_tree.query_ball_point(np.transpose([allsx, allsy, allsz]), dismax) \n",
    "        # various columns in sources \n",
    "        # ragal, decgal, e1gal, e2gal, wgal, rms_egal, mgal, c1gal, c2gal, R2gal, zphotgal\n",
    "        # looping over all the galaxies\n",
    "        for igal in range(Ngal):    \n",
    "            ragal    = datagal[igal,0]\n",
    "            decgal   = datagal[igal,1]\n",
    "            e1gal    = datagal[igal,2]\n",
    "            e2gal    = datagal[igal,3]\n",
    "            wgal     = datagal[igal,4]\n",
    "            rms_egal = datagal[igal,5]\n",
    "            zphotgal = datagal[igal,6]\n",
    "           \n",
    "            # array of lenses indices\n",
    "            lidx = np.array(slidx[igal])\n",
    "            # removing sources which doesn't have any lenses around them \n",
    "            if len(lidx)==0:\n",
    "                continue\n",
    "           \n",
    "            # selecting a cleaner background\n",
    "            zcut = (lred[lidx] < (zphotgal - zdiff)) #only taking the foreground lenses\n",
    "            # again skipping the onces which doesn't satisfy the above criteria\n",
    "            if np.sum(zcut)==0.0:\n",
    "                continue\n",
    "            # collecting the  data of lenses around individual source\n",
    "            lidx   = lidx[zcut] # this will catch the array indices for our lenses\n",
    "            sra    = ragal\n",
    "            sdec   = decgal\n",
    "            \n",
    "            l_ra   = lra[lidx]\n",
    "            l_dec  = ldec[lidx]\n",
    "            l_zred = lred[lidx] \n",
    "            l_wgt  = lwgt[lidx] \n",
    "           \n",
    "            sx, sy, sz = get_xyz(sra,sdec) # individual galaxy ra,dec-->x,y,z\n",
    "            lx, ly, lz = get_xyz(l_ra,l_dec) # individual galaxy ra,dec-->x,y,z\n",
    "            \n",
    "            # getting the radial separations for a lense source pair \n",
    "            sl_sep = np.sqrt((lx - sx)**2 + (ly - sy)**2 + (lz - sz)**2)\n",
    "            sl_sep = sl_sep * cc.comoving_distance(l_zred).value\n",
    "            for ll,sep in enumerate(sl_sep):\n",
    "                if sep<rmin or sep>rmax:\n",
    "                    continue\n",
    "                rb = int(np.log10(sep*1.0/rmin)*1/rdiff)\n",
    "               \n",
    "                # get tangantial components given positions and shapes\n",
    "                e_t = get_et(lra = l_ra[ll], ldec = l_dec[ll], sra = sra, sdec = sdec, se1 = e1gal,  se2 = e2gal)\n",
    "\n",
    "                # sigma_crit_calculations for a given lense-source pair\n",
    "                sigm_crit_inv = get_sigma_crit_inv(l_zred[ll], zphotgal, cc)\n",
    "\n",
    "                # following equations given in the surhud's lectures \n",
    "                w_ls    = l_wgt[ll] * wgal * (sigm_crit_inv)**2\n",
    "                w_ls_by_av_sigc_inv = l_wgt[ll] * wgal * sigm_crit_inv\n",
    "\n",
    "                # separate numerator and denominator computation   \n",
    "                sumdsig_num[rb]   += w_ls_by_av_sigc_inv  * e_t\n",
    "                sumdsigsq_num[rb] += (w_ls_by_av_sigc_inv * e_t)**2\n",
    "                sumwls[rb]        += w_ls\n",
    "                sumwls_resp[rb]   += w_ls * (1-rms_egal**2)\n",
    "\n",
    "        print(ifil)\n",
    "        \n",
    "    outputfile = 'iagrg_dsigma.dat_no_res'  \n",
    "    fout = open(outputfile, \"w\")\n",
    "    fout.write(\"# 0:rmin/2+rmax/2 1:DeltaSigma  2:SN_ErrDeltaSigma\\n\")\n",
    "    for i in range(len(rbins[:-1])):\n",
    "        rrmin = rbins[i]\n",
    "        rrmax = rbins[i+1]\n",
    "        Resp = sumwls_resp[i]*1.0/sumwls[i]\n",
    "        \n",
    "        fout.write(\"%le\\t%le\\t%le\\n\"%(rrmin/2.0+rrmax/2.0, sumdsig_num[i]*1.0/sumwls[i]/2./Resp, np.sqrt(sumdsigsq_num[i])*1.0/sumwls[i]/2./Resp))\n",
    "    fout.write(\"#OK\")    \n",
    "    fout.close()\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the  weak lensing signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
