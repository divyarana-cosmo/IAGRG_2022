{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Get the Weak Lensing Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from the catalog and appying the selection cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lens_select(zmin=0.1, zmax=0.33, lammin=55, lammax=100):\n",
    "    #please check the file path properly \n",
    "    data = pd.read_csv('./DataStore/redmapper.dat', delim_whitespace=1)\n",
    "    #sample selection cut\n",
    "    idx  = (data['lambda']>lammin) & (data['lambda']<=lammax)\n",
    "    idx  = idx & (data['zred']>zmin) & (data['zred']<=zmax)\n",
    "    ra   = data['ra'].values[idx]\n",
    "    dec  = data['dec'].values[idx]\n",
    "    zred = data['zred'].values[idx]\n",
    "    #as we have no weights to apply we set them to unity\n",
    "    wgt  = ra*1.0/ra\n",
    "    print('number of lenses=%d'%len(ra))\n",
    "    return ra, dec, zred, wgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sources(ifil):\n",
    "    # various columns in sources \n",
    "    # ragal, decgal, e1gal, e2gal, wgal, rms_egal, mgal, c1gal, c2gal, R2gal, zphotgal\n",
    "    data = pd.read_csv(ifil, delim_whitespace=1).values\n",
    "    zphotgal = data[:,-1]\n",
    "    # sanity checks on the sources data\n",
    "    idx = (np.sum(np.isnan(data), axis=1)==0) &  (zphotgal>0)\n",
    "    datagal = np.zeros((np.sum(idx),7))\n",
    "    datagal[:,:6] = data[idx,:6]\n",
    "    datagal[:,6]  = data[idx,-1]\n",
    "    # collects only -  ragal, decgal, e1gal, e2gal, wgal, rms_egal, zphotgal\n",
    "    return datagal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the tangential shear $e_{\\rm t}$ and inverse critical density $\\Sigma^{-1}_{\\rm crit}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_et(lra, ldec, sra, sdec, se1, se2):\n",
    "    lra  = lra*np.pi/180\n",
    "    ldec = ldec*np.pi/180\n",
    "    sra  = sra*np.pi/180\n",
    "    sdec = sdec*np.pi/180\n",
    "\n",
    "    c_theta = np.cos(ldec)*np.cos(sdec)*np.cos(lra - sra) + np.sin(ldec)*np.sin(sdec)\n",
    "    s_theta = np.sqrt(1-c_theta**2)\n",
    "\n",
    "    # phi to get the compute the tangential shear\n",
    "    c_phi   = np.cos(ldec)*np.sin(sra - lra)*1.0/s_theta\n",
    "    s_phi   = (-np.sin(ldec)*np.cos(sdec) + np.cos(ldec)*np.cos(sra - lra)*np.sin(sdec))*1.0/s_theta\n",
    "    # tangential shear\n",
    "    e_t     = - se1*(2*c_phi**2 -1) - se2*(2*c_phi * s_phi)\n",
    "\n",
    "    return e_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma_crit_inv(lzred, szred, cc):\n",
    "    # some important constants for the sigma crit computations\n",
    "    gee = 4.301e-9 #km^2 Mpc M_sun^-1 s^-2 gravitational constant\n",
    "    cee = 3e5 #km s^-1\n",
    "    # sigma_crit_calculations for a given lense-source pair\n",
    "    sigm_crit_inv = cc.angular_diameter_distance(lzred).value * cc.angular_diameter_distance_z1z2(lzred, szred).value * (1.0 + lzred)**2 * 1.0/cc.angular_diameter_distance(szred).value\n",
    "    sigm_crit_inv = sigm_crit_inv * 4*np.pi*gee*1.0/cee**2 \n",
    "    sigm_crit_inv = 1e12*sigm_crit_inv #esd's are in pc not in Mpc\n",
    "\n",
    "    return sigm_crit_inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta \\Sigma (R)$ measurements and writing the output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipe(Omegam=0.315, rmin=0.2, rmax=2.0, nbins=10, zdiff=0.4):\n",
    "    #set the cosmology with omegaM parameter \n",
    "    cc = FlatLambdaCDM(H0=100, Om0=Omegam) # fixing H0=100 to set units in Mpc h-1\n",
    "    \n",
    "    # set the projected radial binning \n",
    "    rmin  =  rmin\n",
    "    rmax  =  rmax\n",
    "    nbins = nbins #10 radial bins for our case\n",
    "    rbins  = np.logspace(np.log10(rmin), np.log10(rmax), nbins + 1)\n",
    "    rdiff  = np.log10(rbins[1]*1.0/rbins[0])\n",
    " \n",
    "    # initializing arrays for signal compuations\n",
    "    sumdsig_num   = np.zeros(len(rbins[:-1]))\n",
    "    sumdsigsq_num = np.zeros(len(rbins[:-1]))\n",
    "    sumwls        = np.zeros(len(rbins[:-1]))\n",
    "    sumwls_resp   = np.zeros(len(rbins[:-1]))\n",
    "\n",
    "    # getting the lenses data\n",
    "    lra, ldec, lred, lwgt = lens_select()\n",
    "\n",
    "    # convert lense ra and dec into x,y,z cartesian coordinates\n",
    "    lx, ly, lz = get_xyz(lra, ldec)\n",
    "     \n",
    "    # putting kd tree around the lenses\n",
    "    lens_tree = KDTree(np.array([lx, ly, lz]).T)\n",
    "    \n",
    "    \n",
    "    print('lenses tree is ready\\n')\n",
    "    \n",
    "    # setting maximum search radius\n",
    "    dcommin = cc.comoving_distance(np.min(lred)).value\n",
    "    dismax  = (rmax*1.0/(dcommin)) \n",
    "\n",
    "    # lets first catch the file list for sources\n",
    "    sflist = np.sort(glob.glob('./DataStore/hsc/*.dat'))\n",
    "\n",
    "    # Ready to pounce on the source data\n",
    "    for ifil in sflist:\n",
    "        # catching the source data matrix\n",
    "        # please have a check for the columns names\n",
    "        datagal = read_sources(ifil)\n",
    "        Ngal = len(datagal[:,0])  # total number of galaxies in the source file\n",
    "        # first two entries are ra and dec for the sources\n",
    "        allragal  = datagal[:,0]\n",
    "        alldecgal = datagal[:,1]\n",
    "        # ra and dec to x,y,z for sources\n",
    "        allsx, allsy, allsz = get_xyz(allragal, alldecgal)\n",
    "        # query in a ball around individual sources and collect the lenses ids with a maximum radius\n",
    "        slidx = lens_tree.query_ball_point(np.transpose([allsx, allsy, allsz]), dismax) \n",
    "        # various columns in sources \n",
    "        # ragal, decgal, e1gal, e2gal, wgal, rms_egal, mgal, c1gal, c2gal, R2gal, zphotgal\n",
    "        # looping over all the galaxies\n",
    "        for igal in range(Ngal):    \n",
    "            ragal    = datagal[igal,0]\n",
    "            decgal   = datagal[igal,1]\n",
    "            e1gal    = datagal[igal,2]\n",
    "            e2gal    = datagal[igal,3]\n",
    "            wgal     = datagal[igal,4]\n",
    "            rms_egal = datagal[igal,5]\n",
    "            zphotgal = datagal[igal,6]\n",
    "           \n",
    "            # array of lenses indices\n",
    "            lidx = np.array(slidx[igal])\n",
    "            # removing sources which doesn't have any lenses around them \n",
    "            if len(lidx)==0:\n",
    "                continue\n",
    "           \n",
    "            # selecting a cleaner background\n",
    "            zcut = (lred[lidx] < (zphotgal - zdiff)) #only taking the foreground lenses\n",
    "            # again skipping the onces which doesn't satisfy the above criteria\n",
    "            if np.sum(zcut)==0.0:\n",
    "                continue\n",
    "            # collecting the  data of lenses around individual source\n",
    "            lidx   = lidx[zcut] # this will catch the array indices for our lenses\n",
    "            sra    = ragal\n",
    "            sdec   = decgal\n",
    "            \n",
    "            l_ra   = lra[lidx]\n",
    "            l_dec  = ldec[lidx]\n",
    "            l_zred = lred[lidx] \n",
    "            l_wgt  = lwgt[lidx] \n",
    "           \n",
    "            sx, sy, sz = get_xyz(sra,sdec) # individual galaxy ra,dec-->x,y,z\n",
    "            lx, ly, lz = get_xyz(l_ra,l_dec) # individual galaxy ra,dec-->x,y,z\n",
    "            \n",
    "            # getting the radial separations for a lense source pair \n",
    "            sl_sep = np.sqrt((lx - sx)**2 + (ly - sy)**2 + (lz - sz)**2)\n",
    "            sl_sep = sl_sep * cc.comoving_distance(l_zred).value\n",
    "            for ll,sep in enumerate(sl_sep):\n",
    "                if sep<rmin or sep>rmax:\n",
    "                    continue\n",
    "                rb = int(np.log10(sep*1.0/rmin)*1/rdiff)\n",
    "               \n",
    "                # get tangantial components given positions and shapes\n",
    "                e_t = get_et(lra = l_ra[ll], ldec = l_dec[ll], sra = sra, sdec = sdec, se1 = e1gal,  se2 = e2gal)\n",
    "\n",
    "                # sigma_crit_calculations for a given lense-source pair\n",
    "                sigm_crit_inv = get_sigma_crit_inv(l_zred[ll], zphotgal, cc)\n",
    "\n",
    "                # following equations given in the surhud's lectures \n",
    "                w_ls    = l_wgt[ll] * wgal * (sigm_crit_inv)**2\n",
    "                w_ls_by_av_sigc_inv = l_wgt[ll] * wgal * sigm_crit_inv\n",
    "\n",
    "                # separate numerator and denominator computation   \n",
    "                sumdsig_num[rb]   += w_ls_by_av_sigc_inv  * e_t\n",
    "                sumdsigsq_num[rb] += (w_ls_by_av_sigc_inv * e_t)**2\n",
    "                sumwls[rb]        += w_ls\n",
    "                sumwls_resp[rb]   += w_ls * (1-rms_egal**2)\n",
    "\n",
    "        print(ifil)\n",
    "        \n",
    "    outputfile = 'iagrg_dsigma.dat_no_res'  \n",
    "    fout = open(outputfile, \"w\")\n",
    "    fout.write(\"# 0:rmin/2+rmax/2 1:DeltaSigma  2:SN_ErrDeltaSigma\\n\")\n",
    "    for i in range(len(rbins[:-1])):\n",
    "        rrmin = rbins[i]\n",
    "        rrmax = rbins[i+1]\n",
    "        Resp = sumwls_resp[i]*1.0/sumwls[i]\n",
    "        \n",
    "        fout.write(\"%le\\t%le\\t%le\\n\"%(rrmin/2.0+rrmax/2.0, sumdsig_num[i]*1.0/sumwls[i]/2./Resp, np.sqrt(sumdsigsq_num[i])*1.0/sumwls[i]/2./Resp))\n",
    "    fout.write(\"#OK\")    \n",
    "    fout.close()\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the  weak lensing signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
